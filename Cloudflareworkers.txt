00:00:00	hey everyone welcome to this free course where I'm going to teach you everything you need to know about cloudflare workers in the next hour or so we're going to walk through creating a new Cloud flare account making your first Cloud flare workers application and even adding some interesting stuff like Hano a full stack application framework for workers as well as some Nifty AI tools from cloudflare AI the only prerequisites for this course are that you have some basic command line knowledge as well as some knowledge of

00:00:24	writing JavaScript though if you're not an expert that's totally fine we'll walk through things slowly so that you can understand what's going on and by the end of this you should have a really cool and interesting application that uses Cloud flare and workers AI to build some sort of interesting AI generated text that you can use whether it's an API for Json serving Json responses or in a UI that you can kind of send to people and show off uh using AI tools directly inside of the application so I

00:00:49	hope you enjoy and if you have any questions leave them in the comments below any source that we write inside of this will be available in the description of this video linked to GitHub thanks so much and here's my Twitter right here if you if you want to ask any questions you can reach out to me directly as well so let's jump into it so the first thing we're going to do is set up a new cloudflare account to do that I'll just go to cloudflare.com and I'll click the sign up button now for this you won't need any of the paid uh

00:01:14	any of the paid stuff inside of the Pro Plan or the business plan everything in workers and workers AI is self-served I do believe that workers AI May cost a little bit of money based on your usage but you shouldn't get charg anything for kind of what we're building inside of this uh course but if you want to go through and and double check that and you can also cancel your account afterwards if you don't want to uh incur any extra charges by leaving the account open or something like that so for now

00:01:40	I'll click free once I get to the signup page I'll just enter an email so I'll say Christian cloudflare gmail.com and my password and then I'll click sign up and so now from here it says thank you for choosing cloudflare get this cool little uh Splash uh image and I'll go down here to explore all products and so to start what we're going to do is set up our cloudflare workers uh subdomain and get our account all set up before we actually start generating any code to do this you can go to the sidebar and say

00:02:09	workers and Pages here I'll need to verify my account real quick so I'll come here and check my email so I can click this email verification real quick okay and once my account is verified I'll be able to go back and go to workers and pages and you can see thanks for verifying your email address so from here I can get started creating either my first worker project uh we're going to be working inside of cloudflare workers today which is our serverless functions platform but there is also another tool here called Pages which

00:02:39	allows you to deploy full stack applications like a react application a nextjs application all sorts of other Frameworks and you can do that by either connecting to git so you can connect to GitHub or bitbucket and deploy directly from your repositories or you can upload assets directly so if you have some HTML CSS and JavaScript that you want to um upload you can literally drag and drop it onto the pages uh UI and just deploy it immediately to Cloud fl's Network which is pretty cool so let's start by

00:03:09	creating our first worker and so what I can do is um I can s give it a name here so by default it's worker late Mountain if I refresh here you can see it'll actually get a unique name each time and it'll generate some code as well and you can see what that looks like here and I'll just click deploy and you can see that my first worker has been deployed to region Earth so these are all of the locations that the worker will be served from so it's going to be super low latency and really fast and that's one

00:03:38	of the advantages about deploying with Cloud workers is that your seress functions aren't just deployed to one region they're deployed to all of our different uh sort of points of presence around the world so it'll be super low latency whether you're here in Texas area like I am or you're down in Australia or Asia or wherever you may be wherever your users may be as well it'll be super quick to deploy uh and to get a response back from your applications every single user of cloudflare workers gets their own unique subdomain mine is

00:04:09	Christian cloudfl flare. workers. deev and that's of course based on my uh email that I gave it and so every time you want to deploy workers say you don't have a custom domain available or you want to have sort of a preview or test deployment you can deploy that to this little subdomain here and that way you can sort of keep things um you know maybe you're still working on a project it's not quite done yet or or whatever it may be you have the subdomain that you can deploy things to if I come back

00:04:35	to the worker section here you can see I have a list of all of the different projects I've deployed so as you make more projects this will be uh populated obviously with all the different things you've deployed and if I open up a specific uh worker here I can see all of the information about this worker so things like metrics for requests and sub requests I can configure new routes or all kinds of triggers and things like that here um all of which is explored in our doc documentation which I'll put a

00:05:01	link to in the description and you can check out how that all works okay so now that we've set up our Cloud flare account we verified it and we've even deployed our first worker just to see how that process works let's move to the command line and get started writing code so in order to generate projects for cloud flare workers or even for cloud flare Pages we have a really Nifty tool that I'm going to show you how to use that's kind of a wizard for deploying new workers and Pages applications so all you need to have is

00:05:27	npm installed if you don't know how to do that there is a lot of information in our get started guide which I'll link in the description of the video but all you need to do is run npm create cloudflare and then once you do that you'll be able to and you can see I maybe don't have the most recent version of npm or node that's okay it should still work but uh you can check out the supported versions here and update and upgrade if you need to um but I'm using Create cloudflare version 2.0.8 so at time of recording

00:05:55	that's the version I I'm going to be using I'll show you all the versions that I'm using just in case something changes but it should stay pretty consistent even if there's uh you know new versions of whatever we're trying to use here um so step one of three create an application with cloudflare where do you want to create your application also used as application name so kind of like our other project you'll have a sort of unique uh name for your application which you can either keep just by pressing enter or I can give it a

00:06:23	different name so I'll just call this one workers getting started and then I'll press enter so now we have this directory that's going to be created called workers getting started and now I have a type of application that I want to create so there's a couple highle options here so website or web app that's going to be a cloudflare Pages application so let's say you want to create uh a nextjs project or an astro project or whatever framework you want to use react even um you can do that from directly inside of here you can

00:06:52	also set up a hello world script um that's going to be the one that we're going to use here in just a second as well as common worker functions so if you're new to Cloud flare workers like you probably are if you're watching this video this is a great option to see all the different things that workers can do and then finally we even have a chat GPT plugin uh written in typescript if you want to work with some uh external AI tools so for now I'm going to select hello world script and now will'll ask

00:07:17	me uh two follow-up questions one do I want to use typescript in this case I'll say yes uh it will get started creating the application so it'll copy the files from the template and then it will install dependencies which step two of three it just uses npm so it's everything if you're a JavaScript uh developer that you're familiar with and then finally it'll say do you want to deploy your application uh in this case I'm going to say no and I'll show you why here in just a second uh and you can see that it's uh not going to deploy the

00:07:47	application but in the future I can run npm run deploy if I want to now a couple uh last things that it tells you to check out so one run the development server using npm Run start deploy your application that's npm run deploy read the documentation uh this is developers. cloudflare.com workers which I'll link in the description as well has all sorts of tutorials and reference documentation uh to help you understand workers and how to deploy more things with it and then finally a link to our Discord

00:08:19	discord.gg cloudfare deev which I'll also plug uh at the end of the video as well so there's like I don't know it's a lot of people maybe 40,000 people or something like that in that Discord talking about developing with cloudflare so if you're stuck that's a great place to check out too okay so last thing is we will CD inside of that directory so workers getting started and we can uh take a look at what's inside of this application so we have a node modules folder that's obviously our dependencies

00:08:49	for our project uh package lock. Json and package.json which is our configuration for our JavaScript project uh TS config.js uh since we're using typescript we have a typescript configuration file here and then finally uh the source directory which is obviously our actual application code as well as Wrangler toml which is the configuration for Wrangler so what is Wrangler um so you didn't maybe get a glimpse at it because it was sort of abstracted away Behind these uh npm run scripts but if I open up package.json

00:09:21	here and take a look at it um make this text size a little bit bigger you can see that there's two scripts inside of here so deploy which is just just an alias essentially to Wrangler publish as well as start which is an alias to Wrangler Dev um and then here in the dependencies we have Wrangler 3.0 which is the dependency um for obviously integrating with uh Wrangler so Wrangler is our command line tool for managing all of your cloudflare application stuff whether that's workers or Pages or D1

00:09:54	which is our serverless database KV which is our key Value Store whatever it may be R2 our blob storage provider um there's all sorts of stuff inside of Wrangler you can access it from uh just running npx Wrangler make the text size a little bit smaller here so you can see there's all sorts of stuff here um so like I said there's R2 D1 there's AI models hyperdrive there's all sorts of things in here as well as some um basic uh sub commands for managing your worker as you're building it so Wrangler Dev

00:10:28	starts a local server for devel helping your worker Wrangler deploy is what actually deploys your application Wrangler secret allows you to set uh secret values such as API keys and stuff like that that you don't want to have expos in plain text there's all sorts of things here that you can do inside of the Wrangler um CLI now the first thing we need to do is we actually need to log into cloudflare so we created our project but we're not authenticated yet uh to that cloudflare account that we created and so to do that I'm going to

00:10:56	run npx Wrangler login it's going to actually open a new tab for me automatically and then I'll get shown the screen uh where I can consent to allowing Wrangler to make changes to my cloudflare account so you can see it's going to have access to all this stuff well that's okay I want it to be able to manage basically everything inside of my cloud flare account so I'll say allow and then I'll get redirected here to this page you've granted authorization to Wrangler feel free to uh close this browser window so I'll do that you can

00:11:25	see I successfully logged in and then to make sure I've successfully logged in I'll run npx Wrangler who am I and you can see that it has uh this information you're logged in with an O off token associated with my email Christian cloudflare gmail.com so definitely do this once you authenticate for the first time and make sure that you're connected to the right account or connected to an account at all because that will be what allows you to actually deploy your application now the last thing we need

00:11:52	to do is deploy this application for the first time and to do that I'm going to say npm run deploy which is just going to Shell out here to Wrangler uh publish and you can see here it actually says in this version of Wrangler that Wrangler publish is deprecated and we'll um be moving to Wrangler deploy instead um and so maybe we'll update that here in just a moment but you can see that I have this uh URL here workers getting started. Christian cloudfl flare. workers. deev and if I open it up here

00:12:22	it just returns this uh string hello world back so it took us what uh 1 second to upload it 4 seconds in total to publish it and then at the end of that we already have a uh URL here that is our deployed version of our application so literally 10 seconds 15 seconds or so overall between running npm run deploy and clicking the URL in my command line and I already have something deployed to production which is pretty awesome so next let's look at how we can actually work with our workers application locally in order to

00:12:54	understand uh how we're changing the application and make sure that things work before we deploy it the main command that we use to do that is npx Wrangler Dev or for short npm start which will actually just shell out to Wrangler Dev now what this does is it sets up a local host uh server using a tool called mini flare which is a replication of the server uh sort of isolate technology that we're running on cloud flare servers so when you deploy something to cloudflow workers we have this um you can actually check it out on

00:13:27	GitHub it's called worker d uh it's an open source JavaScript runtime and it will use something very similar locally and in fact you can even pull down the full version of worker D if you want and run it though it is significantly trickier than just using this built-in one um but you can run things locally and see well how is this actually going to work does it work at all uh before you deploy it which is really handy and so you can see that it's running on Local Host 8787 let's open that up you can see on

00:13:56	Local Host 8787 it looks exactly the same as my application that was running uh here in my sort of production URL and so that allows me to test things locally which is great not only does it allow me to do things locally but I can also do things like get logs and uh get live reloads so I'm just running t-mo here to have kind of multiple tabs um that's what that change here is at the bottom but let me open up my file here Source slw worker. TS and let's make a change here and see how it live reloads so I'll

00:14:28	say hello YouTube I'll write that change and then if I refresh here you can see that that uh change has already happened and then if I come back here you can see it Reloaded The Local server as soon as I made a change so I can do true local development and not have to kind of deploy see the change you know make a change locally deploy it again uh etc etc um some other cool things here so right now this is running locally but there are some instances where you do want to actually upload it to Cloud

00:14:58	Flare's um servers and make sure that things work as you'd expect uh the best use case for this is if you're working with things like D1 or KV or something like that where you have this sort of specific um integration that you're doing with one of cloud Flare's other developer tools and you want to make sure that things actually work against those real um real services and so I can test that by pressing the L key which will actually uh turn off the local server and send the uh sort of deployed um test vers version of our application

00:15:30	up to cloudflare specific preview server now what's interesting about this is if I refresh here you can see it's still running at Local Host 8787 the URL hasn't changed but this is actually coming back from one of cloudflare's preview servers and so the way that you can tell this is if I open up my developer tools here you can see I have this get request to my local host path it's exact same uh request I made earlier but if I come to the response headers here and take a look you can see I'm actually getting the CF Ray ID which

00:16:00	is sort of like a unique identifier for this request um as well as the server cloud flare response header so you know that there's actually um a response coming back from cloudflare servers versus just running locally on your own machine so although we have the uh you know true local preview which I can again turn on by just pressing the L key again and and going back to the local server so this is like you know I'm on an airplane and I'm developing locally truly locally and I need to make sure

00:16:28	that I can do everything uh you know on my machine or I can use the uh sort of preview mode in order to ensure that things are working with these external uh Cloud flare services that I want to integrate against and finally um just to show that you can have access to console log and stuff like that let me come back in here and I'll just say console log hello from the local console and I'll write that here again I'll get a Reload um since it has live reload built in and I'll just refresh one more time and I can see

00:16:59	hello from the local console um maybe I'll do something a little bit more interesting here and I will instead console log let's say json.stringify request. CF now um this is something we probably won't cover in this tutorial but there is all sorts of interesting things inside of this request CF parameter um interesting information about the request that's coming in and and all sorts of other things um if I refresh here you can see wow there's a ton of information here um things like uh region here so you can see it's

00:17:32	actually coming from region Texas it even has a postal code attached to it uh an as organization which is the my ISP so this is like my actual ISP that I pay for my home internet and there's all sorts of sort of regional information and stuff like that that's uh really interesting uh score here is actually like a bot score you can see I have this bot management uh object attached I have a score of 99 here which means it's 99% sure that I'm not a bot which is pretty cool so there's all sorts of information

00:18:00	here um that you can use to do um stuff in your application you can sort of conditionally route people uh if I had a score of like 10 and it thought I was a bot for instance I could just terminate the request and just say like you're a bot I don't want you to access uh my application there's all sorts of interesting stuff here that you can check out and that's all in our documentation um which again is linked in the description so finally after I've turned out the after I've removed that console log I'll just press X here and

00:18:26	shut down my local server and so that will um yeah that'll be kind of your introduction to local development which we will use here um as we continue to develop this application so now that we've looked at the basics of creating an application as well as deploying it and previewing it and deplo uh developing against it locally let's actually look at what our workers application code looks like and how to start sort of adding interesting things and building a true application inside of the source code so back in my source

00:18:55	slw worker TS file you can see there's all sorts of comments here here showing how my application works and helping you get started with your application so it says welcome to cloudfl workers here's some instructions here npm runev to start a local development server that's what we just did uh Local Host 8787 we just looked at that as well and then finally npm run deploy to publish a worker so this is all stuff we know at this point I'll just delete this and because we're using typescript you can

00:19:22	see the first thing that gets defined here is this EnV interface so this is where we can add all sorts of bind ings which we'll cover here in a little bit you can sort of think of them as uh bindings to both external services and values so what that means is if I'm connecting to something like R2 or KV all of our external Services um inside of the cloud flare Dev ecosystem that I may want to use inside of this application they are uh kind of referred to as bindings inside of this EnV interface I'll show you what that looks

00:19:54	like in practice when we add some AI uh stuff to this application in a little bit um you can also store uh both text values as well as Secrets inside of these bindings so for instance if you're trying to integrate with an external API like chat GPT or something like that you can set up a secret value that gets um is made available inside of this EnV so for instance like env. uh open AI API key which means that you can use it inside of your application as you would any other variable without it being

00:20:25	available in plain text which is pretty handy um so for now I'm going to clear all of this out though there is great documentation uh in our uh cloudflare workers documentation for how all of these bindings work and and how they get uh sort of added but for now I'm just going to keep this as an empty uh object for now but we can come back and populate this later if we need to now the second part of this is our actual application code so this uh format here is what we call a module worker and essentially what it is is

00:20:56	it's an object that gets exported as the default export of this file now inside of that we have a collection of function handlers which correspond to different events that come into our worker right now we only have one and this is sort of the primary one which is called the fetch event and this represents a new request that's coming in to our workers's application there's other ones such as a scheduled event which is if you set up a sort of cron trigger style uh recurring function so say every hour

00:21:29	you want to run some piece of code um you would set up a new thing here called scheduled and then you would uh you know run whatever code you want inside of that but for now let's just look at the fetch event and it'll be the primary one that we use throughout the rest of this uh tutorial um so inside of that fetch event we have um a couple different parameters so the first of which is request and this represents a uh request coming in to our application you can see it's all typed typed here so we have

00:21:59	this request and we'll be able to check for all sorts of interesting things inside of that and then we also have EnV which is this interface here that's any bindings or anything like that that we've set up and then finally context which has some interesting properties you can check out in the documentation for um sort of configuring how this uh Handler runs for instance when it decides to terminate um after it's done all the stuff that you tell it to do inside of the function body um but for the purposes of this tutorial we won't

00:22:27	really do anything here um finally the response uh signature here um or the return signature for this function is just a promise um so it's asynchronous you can see here from the async keyword and it just returns a response so inside of that we always want to obviously return a response and so that's what we're going to do here we're going to say return new response with the text hello YouTube so we could do all sorts of things here we could say for instance make a database request we could um process input from the request

00:23:00	so if they send us like some data or like a query parameter or something like that we can handle all of that different stuff which I will show you how to do here in a little bit um but ultimately what you need to do here is always return a response so you can kind of think of this as a request comes in a request always comes in with some information maybe that we care about or it's just a a request with no particular interesting information and it always needs to have a response that comes back

00:23:27	so that's sort of the basics there and uh you know as I showed you earlier well we could change this text we could say hello YouTube um we could also do something like return Json so if I wanted to say Json stringify hello uh world and so that's like a a Json payload there that's stringified into text and what I can also do here is add a second parameter which is options for this response and so this can take things like headers for instance which is an object and then I can give it something like content type

00:23:59	which is application sljs so this allows you to do things like for instance send back files or Json or whatever it may be as well as set your own custom headers so you have a lot of different things you can do here in a little bit I'm going to show you how to simplify this using a framework that's super popular in the cloudflare ecosystem called Hano which allows you to have sort of really basic you can literally just say like return c. Json and then it'll just configure everything for you but before we get

00:24:28	that it's good that you understand how to sort of do this from scratch manually kind of the long form way so that when you get into the short version of everything um you still kind of understand what's going on under the hood so finally let's take this version and we'll run npm run deploy it'll bundle everything up uh you can see it's really small so it's gzip down to 22 kilobytes which is a super small application as we start to add dependencies uh this will obviously grow but uh Wrangler will take care of

00:24:59	bundling everything for your application so there's no additional steps there if we come back here and we refresh you can see that this has been updated to a Json uh style payload and so although it looks the same here uh when I make this request if I come here and I just do a curl here and then pipe it into the JQ tool you can see that it's valid Json uh which is great so before we add Hano and make this application a little more interesting let's take a brief look at the last that we haven't looked at yet

00:25:29	in our application which is the Wrangler dotl file so toml if you aren't familiar with it it's sort of configuration uh file format similar to yaml uh that we use internally inside of cloudfare workers applications um there'll also be a Wrangler dojon that's going to be supported here shortly I believe uh sometime this year so if you don't like toml and you don't want to work with it anymore look out for that that's coming soon um but the Tomo file here is what configures our application it has all

00:25:56	sorts of interesting information and it's also well documented so if you open up the Wrangler toml file you can see how everything works and if you need to come back and add something in the future it's likely there'll be good documentation for that that you can check out um both here in the Wrangler tomel file just as like a here's literally how it looks you can come in here and uncomment something if you need to or you can check out the configuration page um inside of our cloudfare workers documentation which

00:26:22	has really in-depth documentation for this file so the things that we have set up here by default are name now name is the um now name is the version here of this URL that sort of gets populated so workers getting started. Christian cloud. workers. deev so that is this workers getting started here that is the name of my application and so that's how that sort of gets translated into the URL Um this can be whatever you want I believe there's probably some limitations probably alpha numeric and stuff like that has to be URL safe but

00:26:55	as long as you don't have another application with the same name here you can call this whatever you want main is the obviously the main file of this project so Source worker. Ts that tells Wrangler where to find the main file and sort of bundle everything that needs to get bundled and then finally the compatibility date so the compatibility date is probably the trickiest part of this um of this file you can basically think of it as sort of the version of your project and more specifically it's

00:27:24	like the version of the workers's runtime that project uses so by default this is going to get set to whatever date you created your application at and as you know you work on this application over time this will sort of stay uh stable right it won't change it's going to be the date that you created your project and what that allows you to do is make sure that um as you continue to work on your project the runtime of uh Cloud FL workers well it may evolve it may have new features it may find bugs

00:27:53	that they want to fix but it may be that your application sort of depends on those bugs right like it's it's meant to be stable so For Better or Worse you may have some feature of like how something in the runtime works that you kind of depend on to work the way that it does and so what the compatibility date is is it sort of locks your application to a specific version of the runtime now the reason that this matters is we have this super in-depth uh compatibility date page in our documentation if you go to

00:28:22	the workers documentation and go to configuration compatibility dates we have this super depth um page that talks about every single sort of change that we've made to the runtime and allows you to kind of opt in to those changes and so for instance if we come down here to the change history you can see we have these lists of things that um that have changed so just a a recent thing here web crypto preserve public exponent field um so let's read this it says in the web crypto API the Public Public

00:28:54	exponent field of the algorithm of RSA Keys would previous be an array buffer using this flag public exponent is a uint 8 array as man mandated by the specification so what is this mean well we had this field here inside of the web crypto API on the workers runtime and we had this field that was of type array buffer well according to specification this should have actually been a uint 8 array and so it may be well I say you're application something with web crypto and you say hey uh I've been building

00:29:25	this it depends on it to be array buffer um so the good news is if you have an application that was uh created before 2023 1201 then uh as long as you keep your compatibility date you know prior to that you aren't going to opt into this change unless you work with this specific flag and so there's an additional thing here we can set up compatibility Flags inside of your Wrangler toml for instance um this flag here is crypto preserve public exponent if you want to enable it uh or no crypto preserve public exponent and so what you

00:30:01	can do here is you can come in and you can add compatibility Flags spelled that wrong compatibility Flags which is just an array and you can sort of opt in piece by piece into whatever specific changes that you need and so that's how compatibility dates and compatibility Flags work um if you want to sort of lock yourself into a specific date just to make sure that nothing changes well all you have to do is nothing basically right just keep your compatibility date the way that it is but if you need to uh

00:30:31	you know have specific changes you want to opt into or you just want to make sure that you're using the most up-to-date version uh of the runtime you can come through and look at all of these changes that are sort of the Delta between what your current compatibility date is and what today's date is and just make sure that all of those changes are things that you don't uh you know depend on in your application um so it's super useful and uh although it's a little confusing to understand at first

00:30:59	it's actually implemented uh pretty straightforward in a way that makes sense so the rest of this here is configuration for different services like KV Nam spaces uh durable objects R2 buckets and if you want to uh check out all of these work we have really great documentation and tutorials to help you understand how to use KV and durable objects and things like that the only thing you really need to understand if I uncomment this out um to sort of understand the the relationship here between the code and the configuration

00:31:29	is that anytime you expose something using a binding uh attribute here for instance my KV namespace the Cory in your code that will become exposed is something like N.Y KV binding so if I have this n. my KV binding I could do things like get uh I could do things like set and where does that come from well it's based on the fact that my KV binding would be defined here inside of my en so like my KV binding it would be something like uh KV namespace or whatever the specific binding is I don't know if that's

00:32:06	exactly what it is but something like that um so that's how that all works um and you can see that the binding here gets exposed like I said here in the N actually think I don't want to delete that I just want to leave it empty so that is the Wrangler configuration file there's a lot of stuff inside of here different bindings um and Integrations as well as links to uh the different services that we have available things like cues um you can actually route to different workers you can call different

00:32:33	workers um from inside of other workers which is pretty cool there's all sorts of things here um and so you can check that out if you want to understand everything you have available to you inside of the workers runtime before we continue throughout the rest of this tutorial we're going to add an AI binding and hopefully do some cool AI stuff here in a little bit but I want to take a slight detour and show you my favorite tool for building applications using Cloud workers which is a full stack framework called Hano so I'll go

00:33:01	to the website here H.D and Hano is actually built by another developer Advocate on my team named yusek he's a really really great developer who is super in tune with the workers runtime and how everything works and he's built this framework that makes it really easy to build applications um you know using Hano inside a cloudflare workers it will save you a ton of code and make things a lot easier to read uh you know it's hash notsponsored or whatever um I just really really enjoy using it it makes my applications a lot

00:33:32	easier to understand and a lot more fun to write um so another benefit is actually runs on any JavaScript runtime so although we're going to be using it here in clafer workers um it works in node it works on uh dino and Bun you can do all sorts of different places and deploy it has all sorts of middleware and things like that you can write your own middleware you can kind of think of it as like Express the uh the node I was going to say the old node framework it's really not that old but you know in in

00:34:00	like web development terms I guess it's old um but it's like Express for cloudflare workers which is really useful it's a really Nifty tool to have so to install it we'll just run npm install Hano and it'll install the package in just a couple seconds now let's actually add it to our application so I'm going to show you is sort of this is the before right this is what the application looks like you recall that it will serve Json back that looks like this hello world with this content type application Json I'm going to show you

00:34:30	the equivalent version inside of Hano so to start I'm going to say import uh Hano from Hano and this will actually be uh whoops let start this over so I'm going to say import and then I'm going to grab the Hano class from inside of the uh Hano package so I'll just wrap that in curly braces here and then I'm going to set up a new instance of my app so I'll say const app equals new Hano um that's going to be my uh app instance and actually I'll put it down here just so it kind of the interfac is up here at

00:35:07	the top and then um because this is typescript I'm going to want to actually uh add this en interface as part of my types so I'm going to say hey I have this EnV um interface I have these custom Bindings that I'm going to be using so make sure that you sort of factor that into how the application thinks about bindings and stuff like that and so to do that what I'm going to do is actually update this right here some angle brackets here and then pass in an object I'm going to say bindings is set to n and so what this will do is

00:35:35	any bindings I put inside of this m will sort of set the types for any bindings inside of my application we'll see how that's useful a little bit later on now we can actually write our first endpoint for our application so I can do that by just saying app.get which takes two different parameters the first of which is the um the the URL or sort of path which is just going to be the root route here slash and then the second thing here is going to be a callback function so this is going to have one argument which is C

00:36:08	you kind of think of this as like context and inside of that I'm just going to return c. Json and then pass in my Json here so hello world and that's all I need to do to return a Json response there's also things like c. text um I believe you can even do uh whoops I believe you can even do c. HTML there's all sorts of different things you can do here uh c.ex c. HTML or cjson and all I have to do here is pass in whatever data I want to have as my Json body it'll take care of stringifying it it'll set all the right

00:36:43	content type headers and everything else that we care about and then all I need to do here is just remove all of this code and export my app as the default uh export of this function and that's all I need to do to set up my Hano app application it's really straightforward and to prove that let's run npm start just like we did earlier we'll set up our Local Host server and if I refresh here you can see I get my content back again hello world let's actually open it up in the um in the network request here and you can see

00:37:18	that I get this content length is set here content type is set both AS application Json with a character set of utf8 so it's significantly less cone to do the same thing 11 lines of cone uh you know even less if you were to like truncate it truly and not do like all of the you know nice spacing and stuff like that um which makes it really straightforward to add uh new functionality to our applications so that's why I really like Hano and I recommend it for most workers developers um to help them get up and running

00:37:48	really quickly so now that we've set up our Hano application let's get started adding our first binding which is going to be the cloudflare AI integration so to begin I'm going to come back here and let's close this local server for now and I'm going to run npm install at cloudflare slai which is our AI package that has all of the stuff that we need to build an application using cloudflare Ai and then the next thing we need to do is set up our first binding so let's open up Wrangler toml and then right

00:38:18	here at the bottom of all of this information here I'm going to set up my AI binding now to do that all I need to do is set up this new section here called AI and then pass in this attribute binding and set it to whatever I want in this case I'll just say AI so The Binding here is set to AI well what is that mean it means that inside of here inside of my en I need to set up Ai and give it the type that matches uh you know the binding for my uh AI integration for now I'll just set this to any um and then what I can do is

00:38:50	integrate my uh AI class from that AI package into my application as well so I'll say import AI from cloudflare AI make sure to match the quotes for people who are catching that on the video um you can see that it gets imported here at Cloud flare AI well what can we do now inside of my uh function Handler here I can set up a integration between the AI binding that we've set up and the AI package that I've installed um from cloudflare AI so I'll say const AI equals new a I and then pass in uh c.n. AI so C.N here is the uh interface

00:39:35	to This n That we've set up here and so anytime that we have a binding set up I'll save this real quick anytime we have a binding setup here in my Wrangler toml such as the AI binding uh it will become available at C.N and so what we're doing here basically is we have this AI class which has been imported from the cloud AI package and this is is going to be sort of the interface to all of our AI models and then we have the c.m. a which is the actual binding to our gpus so this is like sort of magic

00:40:08	code that connects to all the cloud gpus that are running these AI models so with our AI binding setup let's look at how we can actually start using the AI models that we have available in Cloud flare AI so there's all sorts of really interesting models available if you haven't checked it out yet I would go to ai. cloudflare.com and you can see all the cool things that you can build there are things like text generation so we can ask why does so many people like pizza UHA question that has puzzled many

00:40:36	of foodie um so you can generate text and things like that you can do text to image so you can give it some prompt here and say uh cyberpunk cat well let's generate an image that matches that um there's even speech recognition so give it an audio file and translate it uh into text you can sort of do uh like audio to text things like that there's all sorts of different options here and let's go with one of our sort of tried and true um you know the thing that everyone is really excited about with AI

00:41:06	right now which is text generation so this is kind of like your chat GPT or something like that where I give it a question of some kind and I can get some text back that I find kind of Novel or interesting or useful um in this case let's use the CF mistl 7B uh model it's super super good I mean I would say in my experience personally it is comparable to something like GPT 3.5 it's really powerful and quite fast and so in order to do that what we're going to do is use a new um uh function here called ai. run and this takes two

00:41:41	different uh parameters here the first of which is the name of the model and then the second is a inputs um this is going to be where we actually give it our prompt now every model that we run on AI Cloud flare uh is a is a little bit different and so what I would recommend is you go to the documentation so it's just developers. cloudflare.com slw workersworkers D aai and here in the model section we'll have documentation for each individual model so you can see how to uh do text image how to do speech

00:42:14	recognition etc etc in this case let's look at the text generation model here let me shrink this a little bit just so you can see how things look um you can see we have all sorts of models here and and in this case um I'm just going to use the the basic uh looks like this one is using llama but we'll just swap the model out and it should work exactly the same um the important thing here is that we have a couple different arguments here um that you need to pay attention to so first of which we have these

00:42:43	messages now messages is just a list of messages with different roles to help guide the AI in how to run so a system uh message here with a role set to system it says content you are a friendly assistant this sort of guides the output of the AI I could say for instance like you are not a friendly assistant give me wrong answers and it'll probably try and generate wrong answers I could say you are uh you know a personal assistant tasked with helping me achieve uh my professional goals or whatever and it will try and sort of

00:43:15	guide the output to act in that way um so this is optional you don't always have to pass this but can sort of help improve the output that you want from the AI model the second here is the important one which is the user role and this is where you would actually ask it a question or or do something kind of useful or interesting for instance uh what is the origin of the phrase hello world so I'm going to actually copy this I think it's a good starting point um but you can see here the second argument

00:43:41	here to AI run that's that inputs that we started setting up in our code in this case it takes a couple arguments here messages um is going to be the you know these messages and then stream is going to allow us to actually stream output um from the AI so so there's good examples here in the documentation of how to set up stream uh streaming responses I think it's a little out of scope for this introductory tutorial so I won't focus on it here and I just won't provide it I'll just say you know I won't even pass this and it will just

00:44:09	default to um what we'd call a blocking response which means it'll just wait until the the response is completed and then return it to you okay so let's paste in these messages here um so roll system roll user that all looks good um looks like initation H initation is fine it's just my text size that's a little weird um and then inside of my inputs here I'm just going to pass in messages so this is a shorthand here that is sort of equivalent to messages set to messages um I can just sort of shrink it

00:44:42	here like that so we have this inputs which is an object and inside of that we have this messages array now we want to actually capture this response right so we have const response equals ai. run now the issue with this is that this is something that takes time right it's a asynchronous request that needs to go out and talk to Cloud Flare's gpus and run the model and sort of wait for the output to come back and the way that we handle that is by turning this into um first I guess turning this into an

00:45:14	asynchronous function by adding the async parameter or keyword to this callback function and then awaiting the response of this um ai. run that's all we need to do to make this an asynchronous function and now the final thing we need to do is obviously we don't want to just return this hello world back let's actually replace this with the response from our AI model now I already have this uh you know local server running here you can see I'm getting this warning about um how I can run with AI models locally um and says

00:45:50	using workers AI always accesses your Cloud flare account in order to run AI models and so will incur you charges even in local development that's okay um as I said earlier uh if you want to um kind of shut down your account or delete this function or whatever after the fact you can do that if you are worried about incurring charges but for the amount we're using it uh we should incur little to no charges we're going to run this function like once or twice to confirm uh that it works so let's go back to

00:46:17	Local Host I'll refresh here and you can see it's going to take a second it's actually generating output and it's waiting for that response to be completed before it sends it back here to me the user so it says response the phrase hello world is a classic example of a program that prints hello world the console when executed so it's you know an explanation of all this stuff and so that is our first AI uh generated output so if we come back and review what we did here we actually learned a bunch of

00:46:44	interesting stuff just in this little section uh through using the AI integration so first we set up this binding uh we made that available in Wrangler toml by saying binding equal to Ai and and then we imported this AI package and passed in The Binding as sort of the interface to Cloud Flare's uh gpus for running these models second we set up these uh messages and then the input and then altogether we ran ai. run passing in the name of this model here and the inputs to tell it how to guide this AI model into generating some

00:47:18	output here that we called response and returning it here uh in this uh this Json body now this is all good but this is kind of a boring every time I make a request here it's going to do something well not something it's going to do the same thing over and over again which is just answer what is the origin of the phrase hello world so what if we took this and we made it a little bit more interesting I'm going to cut this out here and I'm going to say const content and I'm going to give it that string and

00:47:46	then what I'll do here is I will just pass this as a variable again this is sort of like line 20 where I say this is equivalent to content set to the variable content and I can just drop that here um like that now I might want to have this as uh one option of how to generate um some some content for my AI model but what if I want to actually pass in information what if I want it to be dynamic now the easiest way to do that is if I make a get request to my slash route here right my root path what

00:48:18	I might want to do is support a query parameter I can say query equals you know um how's your day today or something like that right whatever I'm may want to pass in here and so in doing that with workers we would do that with query parameters right so this is equivalent to a query parameter I'm sure you've seen this browsing the web query parameters are very ubiquitous now in vanilla workers what we would do is something like const URL new instance of the URL class we have request.url so let's take the URL that's coming in turn

00:48:48	it into a URL class say URL search parameters get query we' capture all of that and then we'd be able to say say okay this is you know our query here we can actually use it uh inside of our code so there's a lot of stuff you need to do and this is all supported in the documentation by the way you can check that out um but what I love about doing this in Hano is it's super straightforward I can just say something like const content equals c. request. query and then pass in the name of the query parameter here which is just query

00:49:20	and that's all I need to do in order to get that c. request. query now I may want have an actual fallback here so maybe we'll say if that's not set then just say or what is the origin of the phrase hello world and so now I can have Dynamic stuff coming back uh from my AI model to test that let's actually come here and let's set a query parameter so I'll say slash query equals how is your day today I'll press enter oh that did not work uh let's try that I'll add HTTP there there we go my browser decided to

00:49:58	search for it um hello I'm just a computer program so I don't have a physical day but I'm always here to help you with any questions or tasks you have how can I assist you today um so that's funny that's that's pretty straightforward now what I can do here is I can see that it's getting encoded into um into a URL friendly uh you know version of this what I could also do is do this in the command line so maybe I'll say uh curl local actually you know instead of using curl I'll use htd Pi um which is a really popular tool for this

00:50:29	you can do it with curl directly like if I just paste it in that um that thing there I I could do it that way but with HTP what I can do is something like HTTP Local Host 8787 query equals um how do I bake a chocolate chip cookie and all I have to do is pass that in in that format and it'll go and make that request so you see It'll take a second here as it generates that output now now the longer the output is um is going to be the more time it takes to generate that text right and so you may want to move to

00:51:02	streaming so you don't wait for a long long long period of time for it to generate all these instructions so baking chocolate chip cookies is a fun and easy process etc etc and so what I'm doing here by um by running it like this query equals equals how do I bake a chocolate chip cookie you can see that it is actually making a request and in this case it doesn't actually show the query parameter here but you can see it took 16 seconds to generate the text that is uh generating output uh from the

00:51:31	AI based on this query parameter now the final thing we can do is deploy this right so npm run deploy just like we've done in the past but this time we have more interesting information here which is great uh your worker has access to the following bindings we have an AI binding here and it's set to the name AI well that matches what we know here we have c.m. a so we know that that's that's correct right that's the name of our binding and Wrangler has already sort of figured that out and you can

00:52:01	also see that the upload here it's grown significantly in size um still pretty small right 25 kilobytes but it was like .2 kilobytes before why is it uh significantly larger well we've added the Hano package and we've also added the cloud flare AI package so we've added both of those here but ultimately it still gets deployed in just a couple seconds and if I open this URL you can see that it's actually going to generate AI output this time now this case I didn't give it a query parameter of any

00:52:31	any kind so it's going to go back to that fallback talking about hello world but I have deployed this to production now um and I could access this or you could send this to your friends and say you know hey I built an AI application you want to fund fund me for hundred billion dollar or whatever uh you know the space is crazy right now so that's how that all works and with that we've deployed our first kind of interesting uh AI based application with cloud workers using bindings in particular to

00:52:59	connect our workers application to some of the interesting things that we have in the cloud flare ecosystem now last but not least I want to show you some of the cool things you can do with your workers applications once you've actually deployed them so if I go back to this space here and check out um my sort of workers breakdown page for my function you can do all sorts of interesting things with workers applications that we didn't cover here um one of those is custom domains so if you have a cloudflare account where you

00:53:27	have a custom domain connected to it um you can do things like run your workers function uh on a subdomain or even write directly on your domain um for instance that you could set up ai. Christian freeman.com and you could say hey guys this is my AI project um you can run your workers function directly on that domain and it only takes a couple clicks uh in this case I don't have any websites attached to this account right so I I can't do that here um but you can check check out the documentation for

00:53:57	using custom domains and that will allow you to do that um you can also add as we talked about earlier things like Chron triggers say you want to um generate uh some AI response based on some information in your application if you have a database attached or something like that you could say every hour go and query my database get that information back and then I'm going to write this sort of AI uh prompt that says look at all this information and generate some output and maybe you want to like text it to yourself or run it in

00:54:26	a slack um slack Channel or something like that you can do that on a periodic basis using Chron triggers you can also do things uh like email triggers so you can handle incoming mail and say hey if someone sends me an email summarize it using Ai and and write me an email back that says uh here's all the emails you got today and um you know something like that that's actually a project that I've built and if you find that interesting let me know in the comments I would love to do a video on that if you find that

00:54:52	interesting and then finally there's all sorts of other integration you can do here things like cues so you can handle stuff in a queue say you have 100,000 people generating AI responses and you need to start like queuing them up so that your server isn't overrun with requests you can do things like that um you can connect to other workers projects maybe you have another project that you need to be able to call from inside of your application all this stuff is available here and we have documentation for all of it as well and

00:55:21	then the other thing you can do is check out your metrics here so you can see we ran about 11 requests here inside of um you know inside of the uh time in this course somewhat remarkably it seems like I didn't generate any errors in production which might be a first for me in doing a tutorial like this looks like all of my errors were done locally so this is a great chart right now it's looking good you can see how long it takes for things to execute uh how many requests are being made and things like

00:55:50	that there's all kinds of other metrics here if you use our um State and coordination uh tool durable objects uh you can see the metrics for that here as well and again there's all sorts of things you can do here you can see the last time we deployed this was via Wrangler there's a lot of information here that is really helpful so definitely check out this page once you've deployed your application there's all sorts of additional things that you can do here the last two places that I want you to check out are the cloud

00:56:17	flare workers documentation you can find this at developers. cloudflare.com slork and this is document that has been worked on since the beginning of cloudflare workers launching we have years and years of tutorials that you can check out you can do things like uh build open AI models that are fine-tuned you can connect to external uh databases like fauna things like that there are so many tutorials here literally going back it says three years but I can tell you um that I worked on this tutorial uh

00:56:49	almost 5 years ago and so all of these tutorials have stayed up to date there's all kinds of things that you can check out here to build interesting applications using Cloud flare workers and if at any time you get stuck say for things like Wrangler you want to understand more how to use Wrangler or things like what are your configuration options what runtime apis do you have available did you know for instance that we have a whole cache layer that you can use um in order to interface with Cloud

00:57:15	Flare's uh caching layer you can do things like headers or HTML rewriter you can literally take incoming HTML and rewrite it uh in a streaming a inside inside of cloud flare workers you can literally translate things on the Fly um using HTML uh rewriter things like that there's so many things you can do and all of it is available here in the documentation so definitely check that out I think you will find it really interesting in a great Next Step uh in your cloudflare workers Journey uh finally if you go to discord.

00:57:48	cloudflare.com you can join the cloudflare developers Discord there are literally 40,000 people in that Discord which is uh pretty amazing considering I remember when we started it and it was me and our community manager in the Discord now there's 40,000 people in there which is pretty remarkable um and in this Discord you can talk about all of the different Cloud flare developers products so if you built something cool uh I would definitely love to see it in the Discord you can definitely share it

00:58:15	there if you have questions about things like workers AI Wrangler or just deploying applications custom domains whatever it may be it's a great place to ask questions or or if you want to just understand what other people are building with all the cloud developer tools you can do that here as well so just go to discord. cloudflare.com you could probably also just Google search cloudflare Discord I'm sure you can find it there as well and you can join us there and uh and start asking questions and meet the rest of our amazing

00:58:45	community so I hope you found this course interesting and useful let me know in the comments uh if I got anything wrong if there's any typos I'm sure there's one or two of them out there I'll let you know in the description if I have I messed anything up too bad personally speaking love building with cloudflare workers and I'm not just saying that cuz I'm a developer advocate here I think it's one of the quickest ways to get really fun uh applications and ideas out there into production uh all around the world with

00:59:10	low latency and all kinds of uh really awesome and interesting performance characteristics now you know in this tutorial we didn't go into all of the interesting sort of low-level technology stuff about Cloud flare workers but again in our documentation you can check all that stuff out maybe you're interested in Cloud flare workers security model well you can go check that out in the documentation as well you can learn about isolates and all of the cool stuff that we've done um to make Cloud flare workers both secure and

00:59:37	extremely performant so thank you so much for watching uh make sure to subscribe to the cloud flare Channel if you find it interesting and we have all kinds of other videos not just from me but from other developer Advocates uh on the team we're building all sorts of interesting stuff every single day and I'll see you in the next one [Music]

